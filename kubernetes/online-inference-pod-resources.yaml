apiVersion: v1
kind: Pod
metadata:
  name: online-inference-resources
  labels:
    app: online-inference
spec:
    containers:
      - name: heart-classifier-api
        image: garistvlad/heart-classifier-api:v1
        command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
        ports:
          - containerPort: 8000
        resources:
          # max: the running container is not allowed to use more of that resource
          limits:
            memory: "256Mi"
            cpu: "500m"
          # min: are what the container is guaranteed to get
          requests:
            memory: "128Mi"
            cpu: "200m"